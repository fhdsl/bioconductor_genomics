---
title: "02_week2"
format: html
---

## Experimental Design of RNAseq Experiments

A quote from ([Bacher and Kendziorski 2016](https://web.stanford.edu/class/bios221/book/16-chap.html#ref-Bacher:GB:2016)) explains this clearly: "Generally speaking, a well-designed experiment is one that is sufficiently powered and one in which technical artifacts and biological features that may systematically affect measurements are balanced, randomized or controlled in some other way in order to minimize opportunities for multiple explanations for the effect(s) under study."

## Background: Law of large numbers

Define: population, sample, population mean, sample mean, sample variance, effect size.

When the sample size is large, then the sample mean approaches the population mean and the sample variance decreases. This is called the law of large numbers.

The more samples, the better, one might say. But your samples may also relate to variables that may have an impact on the outcome you want to measure.

-   Experimental conditions that relate to your scientific question of interest, such as case vs. control. In the most basic form of differential gene expression analysis, your experimental design should vary at only a single factor of interest.

-   Any relevant metadata, such as age, sex, subtype

-   Batch effects: the date of the experiment conducted, the person who performed the experiment, the reagents used, etc.

-   The sequencing technology

-   The amount of sequencing the sample received (more on this later in Normalization)

-   What else?

This means you need to think carefully what the sample mean and variance is telling you: is it the mean and variability of your experimental condition, or is it the mean and variability of a different variable? (It doesn't have to be exclusive one or the other, as you will see shortly.)

Would you rather: Sequence five replicates on the same cell line, or sequence one replicate each on five different cell lines?

What would the sample variance of each experiment tell you?

Define: biological, technical replicates

Would you rather: Sequence five different samples at 10x coverage, or one sample at 50x coverage?

What would the sample variance of each experiment tell you?

## Confounding

A confounded RNA-Seq experiment is one where you cannot distinguish the separate effects of two different sources of variation in the data.

Example: We know that sex has large effects on gene expression, and if all of our control mice were female and all of the treatment mice were male, then our treatment effect would be confounded by sex. We could not differentiate the effect of treatment from the effect of sex.

Example: We know that batch effect has large effects on gene expression, and if all of our control samples were processed by an experienced researcher on old reagents, and our treatment samples were processed by an trainee researcher on new reagents, our treatment effect would be confounded by (multiple!) batch effects.

Solutions:

-   Ensure that the samples in all experimental conditions have the same values for the confounding variable.

-   If not possible, make sure that all experimental conditions have a similar amount of variability of the confounding variable. (Randomized blocking)

    -   Save this information; we can eliminate these variability in the modeling process.

May also want to consider:

-   Unobserved confounders

-   Propensity score matching

## How do I know how many samples to use?

Define "power", effect size, fold change.

Reference to some packages for power calculations, such as [PROPER](https://bioconductor.org/packages/release/bioc/html/PROPER.html). Takes consideration of:

-   Number of genes measured

-   Number of genes significant

-   Effect size of significant genes

-   Controlled p-value cutoff

-   Default datasets to simulate

-   Number of samples

```{r}
library(PROPER)
sim.opts.Cheung = RNAseq.SimOptions.2grp(ngenes = 20000, p.DE=0.05, lOD="cheung", lBaselineExpr="cheung")
simres = runSims(Nreps = c(3, 5, 7, 10), sim.opts=sim.opts.Cheung, DEmethod="edgeR", nsims=5)
powers = comparePower(simres, alpha.type="fdr", alpha.nominal=0.1, stratify.by="expr", delta=0.5)
summaryPower(powers)
plotPower(powers)
```

This suggests that you get more power out of more samples, rather than sequencing.

The most rigorous power benchmarks are to use controlled labatory experiments, with many samples and sequencing, and then downsample.

## Design matrix

If you are comparing between groups, the simple way is to encode your experimental design the "group" column in colData of your SummarizedExperiment object.

However, if you have more complex designs, such as covariates to control in a blocking design, you will need to create a design matrix:

```{r}
group <- factor(GSE96870$group)
sex <- factor(GSE96870$sex)

design <- model.matrix(~group+sex)
```

Warning: Did you double dip? Are the demarcation of groups I\'m comparing is independent of my molecular measurements? (https://stat.uw.edu/seminars/double-dipping-problems-and-solutions-application-single-cell-rna-sequencing-data, https://anna-neufeld.github.io/datathin/)

## Filtering out low counts

```{r}
#| warning: false
#| message: false
library(SummarizedExperiment)

GSE96870 <- readRDS("data/GSE96870_se.rds")
```

The `filterByExp` function keeps rows that have worthwhile counts in a minumum number
of samples (two samples in this case because the smallest group size is two). The function
accesses the group factor contained in y in order to compute the minimum group size, but
the filtering is performed independently of which sample belongs to which group so that no
bias is introduced.

The filtering should be based on the grouping factors or treatment factors that will be involved
in the differential expression teststested for, rather than on blocking variables that are not
of scientific interest in themselves.

```{r}
library(edgeR)
GSE96870$group = GSE96870$Group

keep = filterByExpr(GSE96870)

GSE96870_kept = GSE96870[keep ,]
GSE96870_notkept = GSE96870[!keep ,]

GSE96870_kept_summary = GSE96870_kept %>% group_by(.feature) %>% summarise(median_count = median(counts),
                                                  mean_count = mean(counts))

summary(GSE96870_kept_summary$median_count)

GSE96870_notkept_summary = GSE96870_notkept %>% group_by(.feature) %>% summarise(median_count = median(counts),
                                                  mean_count = mean(counts))

summary(GSE96870_notkept_summary$median_count)

```

## Dimension Reduction as EDA

```{r}
plotMDS(GSE96870_kept)
```

## 

## Normalization 

"edgeR is concerned with differential expression analysis rather than with the quantification of
expression levels. It is concerned with relative changes in expression levels between conditions,
but not directly with estimating absolute expression levels. This greatly simplifies the technical
influences that need to be taken into account, because any technical factor that is unrelated
to the experimental conditions should cancel out of any differential expression analysis. For
example, read counts can generally be expected to be proportional to length as well as to
expression for any transcript, but edgeR does not generally need to adjust for gene length
because gene length has the same relative influence on the read counts for each RNA sample.
For this reason, normalization issues arise only to the extent that technical factors have
sample-specific effects"

Sample-specific effects addressed

-   Sequencing depth

-   Effective library sizes (also known as RNA composition)

    -    RNA-seq provides a measure of the relative abundance of each gene in each RNA sample, but does not provide any measure of the total RNA output on a per-cell basis - it is a relative measurement. That is, the proportion of reads attributed to a given gene in a library depends on the expression properties of the whole sample rather than just the expression level of that gene.

    -   Then, if a small proportion of highly expressedgenes consume a substantial proportion of the total library size for a particular sample, this will cause the remaining genes to be under-sampled for that sample, confounding DE analysis. The `normLibSizes` function normalizes the library sizes in such a way to minimize the log-fold changes between the samples for most genes.

Other effects that don't vary between sample-sample-length include:

-   Gene length

-   GC content\*

Other ways of normalization out there can be [found here](https://hbctraining.github.io/Intro-to-DGE/lessons/02_DGE_count_normalization.html).

```{r}
result = normLibSizes(GSE96870_kept)

#result2 <- estimateDisp(result)
#plotBCV(result2)
#et <- exactTest(result2, pair=c("Female_Day0", "Male_Day0"))
#topTags(et)
```

Notice that output here is a "DGEList" object, instead of "SummarizedExperiment".

## 
